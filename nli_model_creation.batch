#!/bin/bash
#SBATCH --job-name=ruarepnum_nli_model                            # Job name
#SBATCH --mail-type=END,FAIL                                      # Mail events (NONE, BEGIN, END, FAIL, ALL)
#SBATCH --mail-user=william.aboucaya@inria.fr
#SBATCH --nodes=1                                                 # Run all processes on a single node
#SBATCH --ntasks=1                                                # Run a single task
#SBATCH --cpus-per-task=1                                         # Number of CPU cores per task
#SBATCH --gres=gpu:rtx6000:1                                      # GPU nodes are only available in gpu partition
#SBATCH --mem=24gb                                                 # Total memory allocated
#SBATCH --hint=multithread                                        # we get physical cores not logical
#SBATCH --time=24:00:00                                           # total run time limit (HH:MM:SS)
#SBATCH --output=ruarepnum_nli_model_%j.log                        # Standard output and error log
#SBATCH --partition=gpu

module purge
module load cuda/11.4.0

cd ${SLURM_SUBMIT_DIR}

# Set your conda environment
source /home/$USER/.bashrc
# tensorflow environment shloud bre created previously
source activate ruarepnum

pip install -r requirements.txt | grep -v 'already satisfied'

srun python nli_model_creation.py